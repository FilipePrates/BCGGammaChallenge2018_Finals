{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import metrics\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A ideia nesse notebook (e nos próximos) e criar modelos de feed foward networks no Keras, nesse modelo iremos usar as variáveis numéricas de 2 anos (0709 ou 0911 ou 1113 ou 1315) para tentar predizer o Ideb do ano seguinte aos tais (11,13,15,17 respectivamente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import os dados separados no Gamma7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0709 = pd.read_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\pred_2anos\\train_0709.csv')\n",
    "train0911 = pd.read_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\pred_2anos\\train_0911.csv')\n",
    "train1113 = pd.read_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\pred_2anos\\train_1113.csv')\n",
    "train1315 = pd.read_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\pred_2anos\\train_1315.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred1517 = pd.read_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\pred_2anos\\pred_1517.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar os targets para cada conjunto de anos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0709_target = train0709[['Ideb2011']]\n",
    "train0709.drop(columns=['Ideb2011','Ideb2013','Ideb2015','Ideb2017'],inplace=True)\n",
    "\n",
    "train0911_target = train0911[['Ideb2013']]\n",
    "train0911.drop(columns=['Ideb2007','Ideb2013','Ideb2015','Ideb2017'],inplace=True)\n",
    "\n",
    "train1113_target = train1113[['Ideb2015']]\n",
    "train1113.drop(columns=['Ideb2007','Ideb2009','Ideb2015','Ideb2017'],inplace=True)\n",
    "\n",
    "train1315_target = train1315[['Ideb2017']]\n",
    "train1315.drop(columns=['Ideb2007','Ideb2009','Ideb2011','Ideb2017'],inplace=True)\n",
    "\n",
    "pred1517.drop(columns=['Ideb2007','Ideb2009','Ideb2011','Ideb2013'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'ano_censo0',\n",
       " 'Cod_Escola_Completo',\n",
       " 'regiao0',\n",
       " 'tp_dependencia0',\n",
       " 'num_matriculas0',\n",
       " 'num_estudantes0',\n",
       " 'num_estudantes_ensino_infantil0',\n",
       " 'num_estudantes_ensino_fund_anos_iniciais0',\n",
       " 'num_estudantes_ensino_fund_anos_finais0',\n",
       " 'num_estudantes_fund_1_ano0',\n",
       " 'num_estudantes_fund_2_ano0',\n",
       " 'num_estudantes_fund_3_ano0',\n",
       " 'num_estudantes_fund_4_ano0',\n",
       " 'num_estudantes_fund_5_ano0',\n",
       " 'num_estudantes_fund_6_ano0',\n",
       " 'num_estudantes_fund_7_ano0',\n",
       " 'num_estudantes_fund_8_ano0',\n",
       " 'num_estudantes_fund_9_ano0',\n",
       " 'num_estudantes_medio_1_serie0',\n",
       " 'num_estudantes_medio_2_serie0',\n",
       " 'num_estudantes_medio_3_serie0',\n",
       " 'num_turmas0',\n",
       " 'tp_localizacao0',\n",
       " 'num_salas_existentes0',\n",
       " 'num_salas_utilizadas0',\n",
       " 'num_equip_tv0',\n",
       " 'num_equip_videocassete0',\n",
       " 'num_equip_dvd0',\n",
       " 'num_equip_parabolica0',\n",
       " 'num_equip_copiadora0',\n",
       " 'num_equip_retroprojetor0',\n",
       " 'num_equip_impressora0',\n",
       " 'num_equip_impressora_mult0',\n",
       " 'num_equip_som0',\n",
       " 'num_equip_multimidia0',\n",
       " 'num_equip_fax0',\n",
       " 'num_equip_foto0',\n",
       " 'num_computador0',\n",
       " 'num_comp_administrativo0',\n",
       " 'num_comp_aluno0',\n",
       " 'num_funcionarios0',\n",
       " 'num_professores0',\n",
       " 'num_professores_em_regencia0',\n",
       " 'num_professores_em_regencia_fund_ai0',\n",
       " 'num_professores_em_regencia_fund_af0',\n",
       " 'num_professores_em_regencia_ens_medio0',\n",
       " 'IndicadorRendimento_2015',\n",
       " 'NotaProvaBrasil_NotaMedia_2015',\n",
       " 'Ideb2015',\n",
       " 'Ideb2017',\n",
       " 'is_anosiniciais0',\n",
       " 'ano_censo0.1',\n",
       " 'regiao0.1',\n",
       " 'tp_dependencia0.1',\n",
       " 'num_matriculas0.1',\n",
       " 'num_estudantes0.1',\n",
       " 'num_estudantes_ensino_infantil0.1',\n",
       " 'num_estudantes_ensino_fund_anos_iniciais0.1',\n",
       " 'num_estudantes_ensino_fund_anos_finais0.1',\n",
       " 'num_estudantes_fund_1_ano0.1',\n",
       " 'num_estudantes_fund_2_ano0.1',\n",
       " 'num_estudantes_fund_3_ano0.1',\n",
       " 'num_estudantes_fund_4_ano0.1',\n",
       " 'num_estudantes_fund_5_ano0.1',\n",
       " 'num_estudantes_fund_6_ano0.1',\n",
       " 'num_estudantes_fund_7_ano0.1',\n",
       " 'num_estudantes_fund_8_ano0.1',\n",
       " 'num_estudantes_fund_9_ano0.1',\n",
       " 'num_estudantes_medio_1_serie0.1',\n",
       " 'num_estudantes_medio_2_serie0.1',\n",
       " 'num_estudantes_medio_3_serie0.1',\n",
       " 'num_turmas0.1',\n",
       " 'tp_localizacao0.1',\n",
       " 'num_salas_existentes0.1',\n",
       " 'num_salas_utilizadas0.1',\n",
       " 'num_equip_tv0.1',\n",
       " 'num_equip_videocassete0.1',\n",
       " 'num_equip_dvd0.1',\n",
       " 'num_equip_parabolica0.1',\n",
       " 'num_equip_copiadora0.1',\n",
       " 'num_equip_retroprojetor0.1',\n",
       " 'num_equip_impressora0.1',\n",
       " 'num_equip_impressora_mult0.1',\n",
       " 'num_equip_som0.1',\n",
       " 'num_equip_multimidia0.1',\n",
       " 'num_equip_fax0.1',\n",
       " 'num_equip_foto0.1',\n",
       " 'num_computador0.1',\n",
       " 'num_comp_administrativo0.1',\n",
       " 'num_comp_aluno0.1',\n",
       " 'num_funcionarios0.1',\n",
       " 'num_professores0.1',\n",
       " 'num_professores_em_regencia0.1',\n",
       " 'num_professores_em_regencia_fund_ai0.1',\n",
       " 'num_professores_em_regencia_fund_af0.1',\n",
       " 'num_professores_em_regencia_ens_medio0.1',\n",
       " 'IndicadorRendimento_2017',\n",
       " 'NotaProvaBrasil_NotaMedia_2017',\n",
       " 'is_anosiniciais0.1']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(pred1517.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cod_Escolas = pred1517['Cod_Escola_Completo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropar as colunas não úteis na predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train0709.drop(columns=['Unnamed: 0','ano_censo0','ano_censo0.1','Cod_Escola_Completo','is_anosiniciais0','is_anosiniciais0.1','regiao0','regiao0.1'],inplace=True)\n",
    "train0911.drop(columns=['Unnamed: 0','ano_censo','ano_censo0','Cod_Escola_Completo','is_anosiniciais','is_anosiniciais0','regiao','regiao0'],inplace=True)\n",
    "train1113.drop(columns=['Unnamed: 0','ano_censo','ano_censo0','Cod_Escola_Completo','is_anosiniciais','is_anosiniciais0','regiao','regiao0'],inplace=True)\n",
    "train1315.drop(columns=['Unnamed: 0','ano_censo','ano_censo0','Cod_Escola_Completo','is_anosiniciais','is_anosiniciais0','regiao','regiao0'],inplace=True)\n",
    "\n",
    "pred1517.drop(columns=['Unnamed: 0','ano_censo0','ano_censo0.1','Cod_Escola_Completo','is_anosiniciais0','is_anosiniciais0.1','regiao0','regiao0.1'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizando e scalando os dados para virar a entrada da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Filipe Prates\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\Filipe Prates\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n",
      "C:\\Users\\Filipe Prates\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Filipe Prates\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Filipe Prates\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train0709_s = scale(train0709)\n",
    "train0911_s = scale(train0911)\n",
    "train1113_s = scale(train1113)\n",
    "train1315_s = scale(train1315)\n",
    "\n",
    "pred1517_s = scale(pred1517)\n",
    "\n",
    "pred1517_idebs_s = scale(pred1517_idebs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo treinado com 0709"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como temos muitas features para o modelo, e algumas talvez não tenham tanta influencia na predição quanto outras. Para melhorar a entrada da rede iremos aplicar um PCA nas features de entradas, e iremos usar as 25 primeiras componentes principais, que explicarão quase todas a informação que estava codificada nas features originais (irei repetir esse processo para todos os modelos numéricos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_0709 = PCA(n_components=25)\n",
    "pca_0709.fit(train0709_s)\n",
    "train0709_t = pca_0709.transform(train0709_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0709, X_test_0709, y_train_0709, y_test_0709 = train_test_split(train0709_t,train0709_target,test_size=0.1,random_state=932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0709 = Sequential()\n",
    "n_cols = X_train_0709.shape[1]\n",
    "model_0709.add(Dense(45,activation='relu',input_shape = (n_cols,)))\n",
    "model_0709.add(Dense(33,activation='relu',input_shape = (n_cols,)))\n",
    "#model_0709.add(Dense(13,activation='relu',input_shape = (n_cols,)))\n",
    "model_0709.add(Dense(1))\n",
    "early_stopping_monitor = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23835 samples, validate on 5959 samples\n",
      "Epoch 1/100\n",
      "23835/23835 [==============================] - 1s 38us/step - loss: 1.5950 - val_loss: 0.4028\n",
      "Epoch 2/100\n",
      "23835/23835 [==============================] - 1s 37us/step - loss: 0.3597 - val_loss: 0.3257\n",
      "Epoch 3/100\n",
      "23835/23835 [==============================] - 1s 40us/step - loss: 0.3080 - val_loss: 0.2989\n",
      "Epoch 4/100\n",
      "23835/23835 [==============================] - 1s 35us/step - loss: 0.2908 - val_loss: 0.2912\n",
      "Epoch 5/100\n",
      "23835/23835 [==============================] - 1s 36us/step - loss: 0.2798 - val_loss: 0.2968\n",
      "Epoch 6/100\n",
      "23835/23835 [==============================] - 1s 35us/step - loss: 0.2752 - val_loss: 0.3090\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203fa43d8d0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0709.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model_0709.fit(X_train_0709,y_train_0709,validation_split = 0.2,epochs=100,callbacks=[early_stopping_monitor],batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311/3311 [==============================] - 0s 13us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.306426020654729"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0709.evaluate(X_test_0709,y_test_0709)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Salvando o modelo para usar no Gamma23 fazer a predição com todos os modelos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0709.save(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\models_keras\\model_0709_num.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo treinado com 0911"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_0911 = PCA(n_components=25)\n",
    "pca_0911.fit(train0911_s)\n",
    "train0911_t = pca_0911.transform(train0911_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0911, X_test_0911, y_train_0911, y_test_0911 = train_test_split(train0911_t,train0911_target,test_size=0.1,random_state=932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0911 = Sequential()\n",
    "n_cols = X_train_0911.shape[1]\n",
    "model_0911.add(Dense(45,activation='relu',input_shape = (n_cols,)))\n",
    "model_0911.add(Dense(23,activation='relu',input_shape = (n_cols,)))\n",
    "#model_0911.add(Dense(13,activation='relu',input_shape = (n_cols,)))\n",
    "model_0911.add(Dense(1))\n",
    "early_stopping_monitor = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23837 samples, validate on 5960 samples\n",
      "Epoch 1/100\n",
      "23837/23837 [==============================] - 1s 41us/step - loss: 1.4240 - val_loss: 0.4121\n",
      "Epoch 2/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.3702 - val_loss: 0.3344\n",
      "Epoch 3/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.3308 - val_loss: 0.3179\n",
      "Epoch 4/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.3106 - val_loss: 0.3101\n",
      "Epoch 5/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.2997 - val_loss: 0.3005\n",
      "Epoch 6/100\n",
      "23837/23837 [==============================] - 1s 32us/step - loss: 0.2953 - val_loss: 0.3003\n",
      "Epoch 7/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.2900 - val_loss: 0.2961\n",
      "Epoch 8/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.2874 - val_loss: 0.2903\n",
      "Epoch 9/100\n",
      "23837/23837 [==============================] - 1s 33us/step - loss: 0.2832 - val_loss: 0.2915\n",
      "Epoch 10/100\n",
      "23837/23837 [==============================] - 1s 32us/step - loss: 0.2831 - val_loss: 0.2855\n",
      "Epoch 11/100\n",
      "23837/23837 [==============================] - 1s 31us/step - loss: 0.2797 - val_loss: 0.2961\n",
      "Epoch 12/100\n",
      "23837/23837 [==============================] - 1s 33us/step - loss: 0.2788 - val_loss: 0.2891\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20380d42cf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0911.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model_0911.fit(X_train_0911,y_train_0911,validation_split = 0.2,epochs=100,callbacks=[early_stopping_monitor],batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311/3311 [==============================] - 0s 15us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.281353554564349"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0911.evaluate(X_test_0911,y_test_0911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0911.save(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\models_keras\\model_0911_num.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo treinado com 1113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1113 = PCA(n_components=25)\n",
    "pca_1113.fit(train1113_s)\n",
    "train1113_t = pca_1113.transform(train1113_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1113, X_test_1113, y_train_1113, y_test_1113 = train_test_split(train1113_t,train1113_target,test_size=0.1,random_state=932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1113 = Sequential()\n",
    "n_cols = X_train_1113.shape[1]\n",
    "model_1113.add(Dense(33,activation='relu',input_shape = (n_cols,)))\n",
    "model_1113.add(Dense(20,activation='relu',input_shape = (n_cols,)))\n",
    "#model_1113.add(Dense(13,activation='relu',input_shape = (n_cols,)))\n",
    "model_1113.add(Dense(1))\n",
    "early_stopping_monitor = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23836 samples, validate on 5959 samples\n",
      "Epoch 1/100\n",
      "23836/23836 [==============================] - 1s 42us/step - loss: 3.2911 - val_loss: 0.6854\n",
      "Epoch 2/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.6950 - val_loss: 0.4606\n",
      "Epoch 3/100\n",
      "23836/23836 [==============================] - 1s 31us/step - loss: 0.4143 - val_loss: 0.3689\n",
      "Epoch 4/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.3367 - val_loss: 0.3298\n",
      "Epoch 5/100\n",
      "23836/23836 [==============================] - 1s 31us/step - loss: 0.3119 - val_loss: 0.3094\n",
      "Epoch 6/100\n",
      "23836/23836 [==============================] - 1s 31us/step - loss: 0.3121 - val_loss: 0.3071\n",
      "Epoch 7/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.3282 - val_loss: 0.2948\n",
      "Epoch 8/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.3165 - val_loss: 0.2857\n",
      "Epoch 9/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.2953 - val_loss: 0.2846\n",
      "Epoch 10/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.2841 - val_loss: 0.2852\n",
      "Epoch 11/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.2865 - val_loss: 0.2835\n",
      "Epoch 12/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.2774 - val_loss: 0.2760\n",
      "Epoch 13/100\n",
      "23836/23836 [==============================] - 1s 32us/step - loss: 0.2825 - val_loss: 0.2782\n",
      "Epoch 14/100\n",
      "23836/23836 [==============================] - 1s 33us/step - loss: 0.2761 - val_loss: 0.2763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20389075908>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1113.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model_1113.fit(X_train_1113,y_train_1113,validation_split = 0.2,epochs=100,callbacks=[early_stopping_monitor],batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3311/3311 [==============================] - 0s 14us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2631794283691399"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1113.evaluate(X_test_1113,y_test_1113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1113.save(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\models_keras\\model_1113_num.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo treinado com 1315"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_1315 = PCA(n_components=25)\n",
    "pca_1315.fit(train1315_s)\n",
    "train1315_t = pca_1315.transform(train1315_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1315, X_test_1315, y_train_1315, y_test_1315 = train_test_split(train1315_t,train1315_target,test_size=0.1,random_state=932)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1315 = Sequential()\n",
    "n_cols = X_train_1315.shape[1]\n",
    "model_1315.add(Dense(48,activation='relu',input_shape = (n_cols,)))\n",
    "model_1315.add(Dense(23,activation='relu',input_shape = (n_cols,)))\n",
    "#model_1315.add(Dense(13,activation='relu',input_shape = (n_cols,)))\n",
    "model_1315.add(Dense(1))\n",
    "early_stopping_monitor = EarlyStopping(patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23824 samples, validate on 5957 samples\n",
      "Epoch 1/100\n",
      "23824/23824 [==============================] - 1s 45us/step - loss: 3.1583 - val_loss: 0.7993\n",
      "Epoch 2/100\n",
      "23824/23824 [==============================] - 1s 33us/step - loss: 0.6287 - val_loss: 0.4766\n",
      "Epoch 3/100\n",
      "23824/23824 [==============================] - 1s 33us/step - loss: 0.3963 - val_loss: 0.3934\n",
      "Epoch 4/100\n",
      "23824/23824 [==============================] - 1s 34us/step - loss: 0.3473 - val_loss: 0.3444\n",
      "Epoch 5/100\n",
      "23824/23824 [==============================] - 1s 33us/step - loss: 0.3226 - val_loss: 0.3176\n",
      "Epoch 6/100\n",
      "23824/23824 [==============================] - 1s 36us/step - loss: 0.3272 - val_loss: 0.3077\n",
      "Epoch 7/100\n",
      "23824/23824 [==============================] - 1s 45us/step - loss: 0.3233 - val_loss: 0.3026\n",
      "Epoch 8/100\n",
      "23824/23824 [==============================] - 1s 40us/step - loss: 0.3306 - val_loss: 0.2847\n",
      "Epoch 9/100\n",
      "23824/23824 [==============================] - 1s 38us/step - loss: 0.3190 - val_loss: 0.2881\n",
      "Epoch 10/100\n",
      "23824/23824 [==============================] - 1s 39us/step - loss: 0.3141 - val_loss: 0.2934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2038cfc1f28>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1315.compile(optimizer='adam',loss='mean_squared_error')\n",
    "model_1315.fit(X_train_1315,y_train_1315,validation_split = 0.2,epochs=100,callbacks=[early_stopping_monitor],batch_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3309/3309 [==============================] - 0s 16us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2967785579645227"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1315.evaluate(X_test_1315,y_test_1315)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1315.save(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\models_keras\\model_1315_num.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vendo resultado dos modelos na base 1517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0709_t = pca_0709.transform(pred1517_s)\n",
    "pred0911_t = pca_0911.transform(pred1517_s)\n",
    "pred1113_t = pca_1113.transform(pred1517_s)\n",
    "pred1315_t = pca_1315.transform(pred1517_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred0709_t).to_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\dados_predicao\\pred0709_t_num.csv')\n",
    "pd.DataFrame(pred0911_t).to_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\dados_predicao\\pred0911_t_num.csv')\n",
    "pd.DataFrame(pred1113_t).to_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\dados_predicao\\pred1113_t_num.csv')\n",
    "pd.DataFrame(pred1315_t).to_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\dados_predicao\\pred1315_t_num.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_0709 = pd.Series(data=model_0709.predict(pred0709_t)[:,0])\n",
    "pred_0911 = pd.Series(data=model_0911.predict(pred0911_t)[:,0])\n",
    "pred_1113 = pd.Series(data=model_1113.predict(pred1113_t)[:,0])\n",
    "pred_1315 = pd.Series(data=model_1315.predict(pred1315_t)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideb2011_media = 4.679378 #train0709_target.mean()\n",
    "ideb2013_media = 4.827755 #train0911_target.mean()\n",
    "ideb2015_media = 5.131154 #train1113_target.mean()\n",
    "ideb2017_media = 5.352877 #train1315_target.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os modelos foram treinados à regredir para o valor do ano seguinte, como a média dos Idebs mudam de ano a ano, o modelo treinado com o Ideb2011 como target, por exemplo, tende a dar notas do Ideb perto da média do Ideb2011.\n",
    "\n",
    "Para corrigir esse viés, iremos ver a diferença do valor previsto para a média do IdebTarget do modelo, e aplicaremos essa diferença ao Ideb2017, depois ainda multiplicaremos pela constante de aumento de Ideb, assumindo que continuará aumentando parecido com os anos passados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cte = (5.352877/5.131154 + 5.131154/4.827755 + 4.827755/4.679378)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0459215257160788"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame()\n",
    "output['pred_0709'] = (pred1517['Ideb2017'].mean() + (pred_0709 - ideb2011_media))*cte\n",
    "output['pred_0911'] = (pred1517['Ideb2017'].mean() + (pred_0911 - ideb2013_media))*cte\n",
    "output['pred_1113'] = (pred1517['Ideb2017'].mean() + (pred_1113 - ideb2015_media))*cte\n",
    "output['pred_1315'] = (pred1517['Ideb2017'].mean() + (pred_1315 - ideb2017_media))*cte\n",
    "output['ensemble'] = ((output['pred_0709']+output['pred_0911']+output['pred_1113']+output['pred_1315'])/4)\n",
    "output['Ideb2017'] = pred1517['Ideb2017'] \n",
    "output['dif'] = output['ensemble'] - output['Ideb2017']\n",
    "output['Cod_Escola'] = Cod_Escolas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x20380ec7898>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "output['dif'].hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0709</th>\n",
       "      <th>pred_0911</th>\n",
       "      <th>pred_1113</th>\n",
       "      <th>pred_1315</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>Ideb2017</th>\n",
       "      <th>dif</th>\n",
       "      <th>Cod_Escola</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>33092.000000</td>\n",
       "      <td>33092.000000</td>\n",
       "      <td>33092.000000</td>\n",
       "      <td>33092.000000</td>\n",
       "      <td>33092.000000</td>\n",
       "      <td>33092.000000</td>\n",
       "      <td>33092.000000</td>\n",
       "      <td>3.309200e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.757081</td>\n",
       "      <td>5.643177</td>\n",
       "      <td>5.567036</td>\n",
       "      <td>5.593109</td>\n",
       "      <td>5.640101</td>\n",
       "      <td>5.352844</td>\n",
       "      <td>0.287257</td>\n",
       "      <td>3.302630e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.011615</td>\n",
       "      <td>0.999510</td>\n",
       "      <td>0.999002</td>\n",
       "      <td>1.096931</td>\n",
       "      <td>1.010481</td>\n",
       "      <td>1.101268</td>\n",
       "      <td>0.290051</td>\n",
       "      <td>9.648159e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.455069</td>\n",
       "      <td>2.740963</td>\n",
       "      <td>2.594642</td>\n",
       "      <td>2.095716</td>\n",
       "      <td>2.739929</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>-1.152103</td>\n",
       "      <td>1.100026e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.001543</td>\n",
       "      <td>4.898326</td>\n",
       "      <td>4.790727</td>\n",
       "      <td>4.751007</td>\n",
       "      <td>4.867996</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.105889</td>\n",
       "      <td>2.703248e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.710810</td>\n",
       "      <td>5.606618</td>\n",
       "      <td>5.503328</td>\n",
       "      <td>5.523297</td>\n",
       "      <td>5.584876</td>\n",
       "      <td>5.300000</td>\n",
       "      <td>0.280980</td>\n",
       "      <td>3.303959e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.510005</td>\n",
       "      <td>6.398878</td>\n",
       "      <td>6.339278</td>\n",
       "      <td>6.424258</td>\n",
       "      <td>6.415680</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>0.458947</td>\n",
       "      <td>4.105249e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.412241</td>\n",
       "      <td>17.733371</td>\n",
       "      <td>13.513200</td>\n",
       "      <td>20.657344</td>\n",
       "      <td>12.232172</td>\n",
       "      <td>9.600000</td>\n",
       "      <td>6.432172</td>\n",
       "      <td>5.301462e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred_0709     pred_0911     pred_1113     pred_1315      ensemble  \\\n",
       "count  33092.000000  33092.000000  33092.000000  33092.000000  33092.000000   \n",
       "mean       5.757081      5.643177      5.567036      5.593109      5.640101   \n",
       "std        1.011615      0.999510      0.999002      1.096931      1.010481   \n",
       "min        2.455069      2.740963      2.594642      2.095716      2.739929   \n",
       "25%        5.001543      4.898326      4.790727      4.751007      4.867996   \n",
       "50%        5.710810      5.606618      5.503328      5.523297      5.584876   \n",
       "75%        6.510005      6.398878      6.339278      6.424258      6.415680   \n",
       "max       10.412241     17.733371     13.513200     20.657344     12.232172   \n",
       "\n",
       "           Ideb2017           dif    Cod_Escola  \n",
       "count  33092.000000  33092.000000  3.309200e+04  \n",
       "mean       5.352844      0.287257  3.302630e+07  \n",
       "std        1.101268      0.290051  9.648159e+06  \n",
       "min        1.600000     -1.152103  1.100026e+07  \n",
       "25%        4.600000      0.105889  2.703248e+07  \n",
       "50%        5.300000      0.280980  3.303959e+07  \n",
       "75%        6.200000      0.458947  4.105249e+07  \n",
       "max        9.600000      6.432172  5.301462e+07  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organizar os samples e as predições por diferença entre Ideb2019 previsto e o Ideb2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0709</th>\n",
       "      <th>pred_0911</th>\n",
       "      <th>pred_1113</th>\n",
       "      <th>pred_1315</th>\n",
       "      <th>ensemble</th>\n",
       "      <th>Ideb2017</th>\n",
       "      <th>dif</th>\n",
       "      <th>Cod_Escola</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16114</th>\n",
       "      <td>17.526509</td>\n",
       "      <td>13.455114</td>\n",
       "      <td>13.295857</td>\n",
       "      <td>10.263385</td>\n",
       "      <td>13.635216</td>\n",
       "      <td>5.8</td>\n",
       "      <td>7.835216</td>\n",
       "      <td>33078238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10202</th>\n",
       "      <td>8.841345</td>\n",
       "      <td>19.190076</td>\n",
       "      <td>7.703472</td>\n",
       "      <td>7.739180</td>\n",
       "      <td>10.868518</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.668518</td>\n",
       "      <td>41014375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24821</th>\n",
       "      <td>6.783746</td>\n",
       "      <td>13.695180</td>\n",
       "      <td>5.992169</td>\n",
       "      <td>4.917863</td>\n",
       "      <td>7.847240</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.647240</td>\n",
       "      <td>21233594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26795</th>\n",
       "      <td>5.209882</td>\n",
       "      <td>5.362359</td>\n",
       "      <td>5.062915</td>\n",
       "      <td>4.590098</td>\n",
       "      <td>5.056313</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.456313</td>\n",
       "      <td>26048841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13740</th>\n",
       "      <td>7.709617</td>\n",
       "      <td>7.233768</td>\n",
       "      <td>5.051186</td>\n",
       "      <td>3.923553</td>\n",
       "      <td>5.979531</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.179531</td>\n",
       "      <td>22014802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23925</th>\n",
       "      <td>4.666467</td>\n",
       "      <td>4.343467</td>\n",
       "      <td>4.427411</td>\n",
       "      <td>4.207129</td>\n",
       "      <td>4.411119</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.111119</td>\n",
       "      <td>13055810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26498</th>\n",
       "      <td>4.527168</td>\n",
       "      <td>4.328674</td>\n",
       "      <td>4.078187</td>\n",
       "      <td>3.685744</td>\n",
       "      <td>4.154943</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.054943</td>\n",
       "      <td>22067779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18726</th>\n",
       "      <td>10.013118</td>\n",
       "      <td>8.249812</td>\n",
       "      <td>5.948888</td>\n",
       "      <td>4.840933</td>\n",
       "      <td>7.263188</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.963188</td>\n",
       "      <td>33027188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3.608334</td>\n",
       "      <td>4.151026</td>\n",
       "      <td>3.535019</td>\n",
       "      <td>3.356188</td>\n",
       "      <td>3.662642</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.962642</td>\n",
       "      <td>11001844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6581</th>\n",
       "      <td>4.123899</td>\n",
       "      <td>4.496779</td>\n",
       "      <td>3.317009</td>\n",
       "      <td>3.266781</td>\n",
       "      <td>3.801117</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.901117</td>\n",
       "      <td>33100659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28222</th>\n",
       "      <td>5.316122</td>\n",
       "      <td>5.645866</td>\n",
       "      <td>5.274981</td>\n",
       "      <td>9.360297</td>\n",
       "      <td>6.399317</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.899317</td>\n",
       "      <td>33053073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21717</th>\n",
       "      <td>4.162325</td>\n",
       "      <td>3.745729</td>\n",
       "      <td>3.848471</td>\n",
       "      <td>3.289763</td>\n",
       "      <td>3.761572</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.861572</td>\n",
       "      <td>29165270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24349</th>\n",
       "      <td>5.223934</td>\n",
       "      <td>6.438889</td>\n",
       "      <td>6.346614</td>\n",
       "      <td>6.205279</td>\n",
       "      <td>6.053679</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.853679</td>\n",
       "      <td>21229767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>4.947389</td>\n",
       "      <td>4.836513</td>\n",
       "      <td>4.053780</td>\n",
       "      <td>4.529350</td>\n",
       "      <td>4.591758</td>\n",
       "      <td>2.8</td>\n",
       "      <td>1.791758</td>\n",
       "      <td>33040141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6000</th>\n",
       "      <td>3.495910</td>\n",
       "      <td>3.693864</td>\n",
       "      <td>3.270199</td>\n",
       "      <td>3.382964</td>\n",
       "      <td>3.460734</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.760734</td>\n",
       "      <td>28015355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14197</th>\n",
       "      <td>6.508443</td>\n",
       "      <td>6.723553</td>\n",
       "      <td>7.340953</td>\n",
       "      <td>7.196637</td>\n",
       "      <td>6.942397</td>\n",
       "      <td>5.2</td>\n",
       "      <td>1.742397</td>\n",
       "      <td>23004584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>3.712199</td>\n",
       "      <td>3.989711</td>\n",
       "      <td>3.662448</td>\n",
       "      <td>3.777706</td>\n",
       "      <td>3.785516</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.685516</td>\n",
       "      <td>28004701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14546</th>\n",
       "      <td>4.873428</td>\n",
       "      <td>5.024653</td>\n",
       "      <td>5.396584</td>\n",
       "      <td>5.421579</td>\n",
       "      <td>5.179061</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.679061</td>\n",
       "      <td>26146916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15836</th>\n",
       "      <td>6.507610</td>\n",
       "      <td>6.853807</td>\n",
       "      <td>5.746859</td>\n",
       "      <td>6.740792</td>\n",
       "      <td>6.462267</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.662267</td>\n",
       "      <td>32059833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14922</th>\n",
       "      <td>3.247937</td>\n",
       "      <td>3.474188</td>\n",
       "      <td>3.414164</td>\n",
       "      <td>2.862918</td>\n",
       "      <td>3.249802</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.649802</td>\n",
       "      <td>29233666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>3.330248</td>\n",
       "      <td>3.689200</td>\n",
       "      <td>3.419989</td>\n",
       "      <td>3.724189</td>\n",
       "      <td>3.540906</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.640906</td>\n",
       "      <td>28016360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1165</th>\n",
       "      <td>3.917928</td>\n",
       "      <td>4.395588</td>\n",
       "      <td>3.704869</td>\n",
       "      <td>3.738591</td>\n",
       "      <td>3.939244</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.639244</td>\n",
       "      <td>31099171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>3.422543</td>\n",
       "      <td>3.629567</td>\n",
       "      <td>3.652104</td>\n",
       "      <td>3.027391</td>\n",
       "      <td>3.432901</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.632901</td>\n",
       "      <td>15136060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13825</th>\n",
       "      <td>6.400981</td>\n",
       "      <td>7.185278</td>\n",
       "      <td>7.392956</td>\n",
       "      <td>7.044588</td>\n",
       "      <td>7.005951</td>\n",
       "      <td>5.4</td>\n",
       "      <td>1.605951</td>\n",
       "      <td>23191830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3499</th>\n",
       "      <td>4.265707</td>\n",
       "      <td>4.764709</td>\n",
       "      <td>4.008062</td>\n",
       "      <td>3.675334</td>\n",
       "      <td>4.178453</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.578453</td>\n",
       "      <td>31068675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10805</th>\n",
       "      <td>4.188760</td>\n",
       "      <td>4.250139</td>\n",
       "      <td>4.039229</td>\n",
       "      <td>4.167871</td>\n",
       "      <td>4.161500</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.561500</td>\n",
       "      <td>31119008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3477</th>\n",
       "      <td>4.192981</td>\n",
       "      <td>4.599231</td>\n",
       "      <td>3.927718</td>\n",
       "      <td>3.907992</td>\n",
       "      <td>4.156981</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.556981</td>\n",
       "      <td>31130044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21084</th>\n",
       "      <td>4.336545</td>\n",
       "      <td>3.873215</td>\n",
       "      <td>3.965970</td>\n",
       "      <td>3.617329</td>\n",
       "      <td>3.948265</td>\n",
       "      <td>2.4</td>\n",
       "      <td>1.548265</td>\n",
       "      <td>29430356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12017</th>\n",
       "      <td>6.123389</td>\n",
       "      <td>6.780997</td>\n",
       "      <td>6.965536</td>\n",
       "      <td>6.720686</td>\n",
       "      <td>6.647652</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.547652</td>\n",
       "      <td>23021454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6540</th>\n",
       "      <td>4.068285</td>\n",
       "      <td>5.048208</td>\n",
       "      <td>3.617736</td>\n",
       "      <td>3.842480</td>\n",
       "      <td>4.144177</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.544177</td>\n",
       "      <td>33034869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25052</th>\n",
       "      <td>7.587608</td>\n",
       "      <td>7.705831</td>\n",
       "      <td>7.068697</td>\n",
       "      <td>6.985815</td>\n",
       "      <td>7.336988</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-0.863012</td>\n",
       "      <td>23004711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13029</th>\n",
       "      <td>7.742323</td>\n",
       "      <td>7.674551</td>\n",
       "      <td>6.788071</td>\n",
       "      <td>6.713915</td>\n",
       "      <td>7.229715</td>\n",
       "      <td>8.1</td>\n",
       "      <td>-0.870285</td>\n",
       "      <td>27044319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15193</th>\n",
       "      <td>5.033111</td>\n",
       "      <td>4.793189</td>\n",
       "      <td>4.290724</td>\n",
       "      <td>4.393190</td>\n",
       "      <td>4.627553</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.872447</td>\n",
       "      <td>31236730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>5.597727</td>\n",
       "      <td>6.266391</td>\n",
       "      <td>4.914439</td>\n",
       "      <td>4.922079</td>\n",
       "      <td>5.425159</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-0.874841</td>\n",
       "      <td>32030142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14286</th>\n",
       "      <td>5.777957</td>\n",
       "      <td>6.581934</td>\n",
       "      <td>5.723687</td>\n",
       "      <td>6.792267</td>\n",
       "      <td>6.218961</td>\n",
       "      <td>7.1</td>\n",
       "      <td>-0.881039</td>\n",
       "      <td>23170115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16230</th>\n",
       "      <td>6.089415</td>\n",
       "      <td>6.362406</td>\n",
       "      <td>5.276786</td>\n",
       "      <td>4.723687</td>\n",
       "      <td>5.613074</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-0.886926</td>\n",
       "      <td>33074550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>5.269370</td>\n",
       "      <td>5.508651</td>\n",
       "      <td>4.641467</td>\n",
       "      <td>4.607314</td>\n",
       "      <td>5.006701</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-0.893299</td>\n",
       "      <td>11021403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27211</th>\n",
       "      <td>6.778490</td>\n",
       "      <td>6.700264</td>\n",
       "      <td>6.289235</td>\n",
       "      <td>6.245496</td>\n",
       "      <td>6.503371</td>\n",
       "      <td>7.4</td>\n",
       "      <td>-0.896629</td>\n",
       "      <td>29104025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16495</th>\n",
       "      <td>4.851541</td>\n",
       "      <td>4.339174</td>\n",
       "      <td>4.876288</td>\n",
       "      <td>4.333271</td>\n",
       "      <td>4.600068</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-0.899932</td>\n",
       "      <td>35240916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13778</th>\n",
       "      <td>5.269122</td>\n",
       "      <td>5.369635</td>\n",
       "      <td>5.156273</td>\n",
       "      <td>5.804014</td>\n",
       "      <td>5.399761</td>\n",
       "      <td>6.3</td>\n",
       "      <td>-0.900239</td>\n",
       "      <td>22023976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16496</th>\n",
       "      <td>6.113308</td>\n",
       "      <td>5.826927</td>\n",
       "      <td>6.559076</td>\n",
       "      <td>6.293336</td>\n",
       "      <td>6.198162</td>\n",
       "      <td>7.1</td>\n",
       "      <td>-0.901838</td>\n",
       "      <td>35240916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13871</th>\n",
       "      <td>5.819933</td>\n",
       "      <td>6.498973</td>\n",
       "      <td>5.784900</td>\n",
       "      <td>6.095357</td>\n",
       "      <td>6.049791</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-0.950209</td>\n",
       "      <td>23147342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25537</th>\n",
       "      <td>9.034875</td>\n",
       "      <td>8.934632</td>\n",
       "      <td>8.361286</td>\n",
       "      <td>8.267539</td>\n",
       "      <td>8.649583</td>\n",
       "      <td>9.6</td>\n",
       "      <td>-0.950417</td>\n",
       "      <td>27042898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19295</th>\n",
       "      <td>7.154708</td>\n",
       "      <td>7.419477</td>\n",
       "      <td>7.032260</td>\n",
       "      <td>7.352443</td>\n",
       "      <td>7.239722</td>\n",
       "      <td>8.2</td>\n",
       "      <td>-0.960278</td>\n",
       "      <td>35273685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14080</th>\n",
       "      <td>8.157829</td>\n",
       "      <td>8.317946</td>\n",
       "      <td>7.165906</td>\n",
       "      <td>7.258476</td>\n",
       "      <td>7.725040</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-0.974960</td>\n",
       "      <td>23261480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16594</th>\n",
       "      <td>5.288309</td>\n",
       "      <td>5.009978</td>\n",
       "      <td>4.627063</td>\n",
       "      <td>4.688254</td>\n",
       "      <td>4.903401</td>\n",
       "      <td>5.9</td>\n",
       "      <td>-0.996599</td>\n",
       "      <td>35273673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29655</th>\n",
       "      <td>6.866732</td>\n",
       "      <td>6.350201</td>\n",
       "      <td>7.149600</td>\n",
       "      <td>6.826276</td>\n",
       "      <td>6.798202</td>\n",
       "      <td>7.8</td>\n",
       "      <td>-1.001798</td>\n",
       "      <td>41076680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12445</th>\n",
       "      <td>8.270368</td>\n",
       "      <td>8.886947</td>\n",
       "      <td>8.025236</td>\n",
       "      <td>7.994621</td>\n",
       "      <td>8.294293</td>\n",
       "      <td>9.3</td>\n",
       "      <td>-1.005707</td>\n",
       "      <td>23213434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12280</th>\n",
       "      <td>7.883469</td>\n",
       "      <td>7.782013</td>\n",
       "      <td>6.906537</td>\n",
       "      <td>7.299020</td>\n",
       "      <td>7.467760</td>\n",
       "      <td>8.5</td>\n",
       "      <td>-1.032240</td>\n",
       "      <td>23045280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12882</th>\n",
       "      <td>6.095470</td>\n",
       "      <td>5.708294</td>\n",
       "      <td>5.315886</td>\n",
       "      <td>5.698817</td>\n",
       "      <td>5.704617</td>\n",
       "      <td>6.8</td>\n",
       "      <td>-1.095383</td>\n",
       "      <td>26085275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15580</th>\n",
       "      <td>4.848481</td>\n",
       "      <td>4.375185</td>\n",
       "      <td>5.266108</td>\n",
       "      <td>5.458769</td>\n",
       "      <td>4.987136</td>\n",
       "      <td>6.1</td>\n",
       "      <td>-1.112864</td>\n",
       "      <td>31012858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13019</th>\n",
       "      <td>5.901155</td>\n",
       "      <td>5.689648</td>\n",
       "      <td>5.021764</td>\n",
       "      <td>5.593551</td>\n",
       "      <td>5.551529</td>\n",
       "      <td>6.7</td>\n",
       "      <td>-1.148471</td>\n",
       "      <td>27043452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24998</th>\n",
       "      <td>8.284197</td>\n",
       "      <td>8.216622</td>\n",
       "      <td>7.507700</td>\n",
       "      <td>7.354312</td>\n",
       "      <td>7.840708</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.159292</td>\n",
       "      <td>23160764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14166</th>\n",
       "      <td>8.064399</td>\n",
       "      <td>8.119795</td>\n",
       "      <td>7.098643</td>\n",
       "      <td>6.855401</td>\n",
       "      <td>7.534559</td>\n",
       "      <td>8.7</td>\n",
       "      <td>-1.165441</td>\n",
       "      <td>23001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26513</th>\n",
       "      <td>8.453411</td>\n",
       "      <td>8.618734</td>\n",
       "      <td>7.594258</td>\n",
       "      <td>7.484434</td>\n",
       "      <td>8.037709</td>\n",
       "      <td>9.3</td>\n",
       "      <td>-1.262291</td>\n",
       "      <td>23005653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12034</th>\n",
       "      <td>7.959074</td>\n",
       "      <td>8.014282</td>\n",
       "      <td>7.268750</td>\n",
       "      <td>7.275327</td>\n",
       "      <td>7.629358</td>\n",
       "      <td>8.9</td>\n",
       "      <td>-1.270642</td>\n",
       "      <td>23050403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3900</th>\n",
       "      <td>4.967969</td>\n",
       "      <td>5.334435</td>\n",
       "      <td>6.104998</td>\n",
       "      <td>5.976896</td>\n",
       "      <td>5.596075</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-1.303925</td>\n",
       "      <td>31081639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>7.042744</td>\n",
       "      <td>7.698186</td>\n",
       "      <td>7.500134</td>\n",
       "      <td>7.655243</td>\n",
       "      <td>7.474077</td>\n",
       "      <td>8.8</td>\n",
       "      <td>-1.325923</td>\n",
       "      <td>26018977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>6.554956</td>\n",
       "      <td>6.962838</td>\n",
       "      <td>6.658747</td>\n",
       "      <td>5.456424</td>\n",
       "      <td>6.408241</td>\n",
       "      <td>7.9</td>\n",
       "      <td>-1.491759</td>\n",
       "      <td>53013352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>5.135652</td>\n",
       "      <td>6.597550</td>\n",
       "      <td>5.433270</td>\n",
       "      <td>-1.446468</td>\n",
       "      <td>3.930001</td>\n",
       "      <td>5.7</td>\n",
       "      <td>-1.769999</td>\n",
       "      <td>29181429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33092 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pred_0709  pred_0911  pred_1113  pred_1315   ensemble  Ideb2017  \\\n",
       "16114  17.526509  13.455114  13.295857  10.263385  13.635216       5.8   \n",
       "10202   8.841345  19.190076   7.703472   7.739180  10.868518       5.2   \n",
       "24821   6.783746  13.695180   5.992169   4.917863   7.847240       5.2   \n",
       "26795   5.209882   5.362359   5.062915   4.590098   5.056313       2.6   \n",
       "13740   7.709617   7.233768   5.051186   3.923553   5.979531       3.8   \n",
       "23925   4.666467   4.343467   4.427411   4.207129   4.411119       2.3   \n",
       "26498   4.527168   4.328674   4.078187   3.685744   4.154943       2.1   \n",
       "18726  10.013118   8.249812   5.948888   4.840933   7.263188       5.3   \n",
       "305     3.608334   4.151026   3.535019   3.356188   3.662642       1.7   \n",
       "6581    4.123899   4.496779   3.317009   3.266781   3.801117       1.9   \n",
       "28222   5.316122   5.645866   5.274981   9.360297   6.399317       4.5   \n",
       "21717   4.162325   3.745729   3.848471   3.289763   3.761572       1.9   \n",
       "24349   5.223934   6.438889   6.346614   6.205279   6.053679       4.2   \n",
       "7719    4.947389   4.836513   4.053780   4.529350   4.591758       2.8   \n",
       "6000    3.495910   3.693864   3.270199   3.382964   3.460734       1.7   \n",
       "14197   6.508443   6.723553   7.340953   7.196637   6.942397       5.2   \n",
       "903     3.712199   3.989711   3.662448   3.777706   3.785516       2.1   \n",
       "14546   4.873428   5.024653   5.396584   5.421579   5.179061       3.5   \n",
       "15836   6.507610   6.853807   5.746859   6.740792   6.462267       4.8   \n",
       "14922   3.247937   3.474188   3.414164   2.862918   3.249802       1.6   \n",
       "902     3.330248   3.689200   3.419989   3.724189   3.540906       1.9   \n",
       "1165    3.917928   4.395588   3.704869   3.738591   3.939244       2.3   \n",
       "450     3.422543   3.629567   3.652104   3.027391   3.432901       1.8   \n",
       "13825   6.400981   7.185278   7.392956   7.044588   7.005951       5.4   \n",
       "3499    4.265707   4.764709   4.008062   3.675334   4.178453       2.6   \n",
       "10805   4.188760   4.250139   4.039229   4.167871   4.161500       2.6   \n",
       "3477    4.192981   4.599231   3.927718   3.907992   4.156981       2.6   \n",
       "21084   4.336545   3.873215   3.965970   3.617329   3.948265       2.4   \n",
       "12017   6.123389   6.780997   6.965536   6.720686   6.647652       5.1   \n",
       "6540    4.068285   5.048208   3.617736   3.842480   4.144177       2.6   \n",
       "...          ...        ...        ...        ...        ...       ...   \n",
       "25052   7.587608   7.705831   7.068697   6.985815   7.336988       8.2   \n",
       "13029   7.742323   7.674551   6.788071   6.713915   7.229715       8.1   \n",
       "15193   5.033111   4.793189   4.290724   4.393190   4.627553       5.5   \n",
       "1639    5.597727   6.266391   4.914439   4.922079   5.425159       6.3   \n",
       "14286   5.777957   6.581934   5.723687   6.792267   6.218961       7.1   \n",
       "16230   6.089415   6.362406   5.276786   4.723687   5.613074       6.5   \n",
       "298     5.269370   5.508651   4.641467   4.607314   5.006701       5.9   \n",
       "27211   6.778490   6.700264   6.289235   6.245496   6.503371       7.4   \n",
       "16495   4.851541   4.339174   4.876288   4.333271   4.600068       5.5   \n",
       "13778   5.269122   5.369635   5.156273   5.804014   5.399761       6.3   \n",
       "16496   6.113308   5.826927   6.559076   6.293336   6.198162       7.1   \n",
       "13871   5.819933   6.498973   5.784900   6.095357   6.049791       7.0   \n",
       "25537   9.034875   8.934632   8.361286   8.267539   8.649583       9.6   \n",
       "19295   7.154708   7.419477   7.032260   7.352443   7.239722       8.2   \n",
       "14080   8.157829   8.317946   7.165906   7.258476   7.725040       8.7   \n",
       "16594   5.288309   5.009978   4.627063   4.688254   4.903401       5.9   \n",
       "29655   6.866732   6.350201   7.149600   6.826276   6.798202       7.8   \n",
       "12445   8.270368   8.886947   8.025236   7.994621   8.294293       9.3   \n",
       "12280   7.883469   7.782013   6.906537   7.299020   7.467760       8.5   \n",
       "12882   6.095470   5.708294   5.315886   5.698817   5.704617       6.8   \n",
       "15580   4.848481   4.375185   5.266108   5.458769   4.987136       6.1   \n",
       "13019   5.901155   5.689648   5.021764   5.593551   5.551529       6.7   \n",
       "24998   8.284197   8.216622   7.507700   7.354312   7.840708       9.0   \n",
       "14166   8.064399   8.119795   7.098643   6.855401   7.534559       8.7   \n",
       "26513   8.453411   8.618734   7.594258   7.484434   8.037709       9.3   \n",
       "12034   7.959074   8.014282   7.268750   7.275327   7.629358       8.9   \n",
       "3900    4.967969   5.334435   6.104998   5.976896   5.596075       6.9   \n",
       "867     7.042744   7.698186   7.500134   7.655243   7.474077       8.8   \n",
       "3208    6.554956   6.962838   6.658747   5.456424   6.408241       7.9   \n",
       "939     5.135652   6.597550   5.433270  -1.446468   3.930001       5.7   \n",
       "\n",
       "            dif  Cod_Escola  \n",
       "16114  7.835216    33078238  \n",
       "10202  5.668518    41014375  \n",
       "24821  2.647240    21233594  \n",
       "26795  2.456313    26048841  \n",
       "13740  2.179531    22014802  \n",
       "23925  2.111119    13055810  \n",
       "26498  2.054943    22067779  \n",
       "18726  1.963188    33027188  \n",
       "305    1.962642    11001844  \n",
       "6581   1.901117    33100659  \n",
       "28222  1.899317    33053073  \n",
       "21717  1.861572    29165270  \n",
       "24349  1.853679    21229767  \n",
       "7719   1.791758    33040141  \n",
       "6000   1.760734    28015355  \n",
       "14197  1.742397    23004584  \n",
       "903    1.685516    28004701  \n",
       "14546  1.679061    26146916  \n",
       "15836  1.662267    32059833  \n",
       "14922  1.649802    29233666  \n",
       "902    1.640906    28016360  \n",
       "1165   1.639244    31099171  \n",
       "450    1.632901    15136060  \n",
       "13825  1.605951    23191830  \n",
       "3499   1.578453    31068675  \n",
       "10805  1.561500    31119008  \n",
       "3477   1.556981    31130044  \n",
       "21084  1.548265    29430356  \n",
       "12017  1.547652    23021454  \n",
       "6540   1.544177    33034869  \n",
       "...         ...         ...  \n",
       "25052 -0.863012    23004711  \n",
       "13029 -0.870285    27044319  \n",
       "15193 -0.872447    31236730  \n",
       "1639  -0.874841    32030142  \n",
       "14286 -0.881039    23170115  \n",
       "16230 -0.886926    33074550  \n",
       "298   -0.893299    11021403  \n",
       "27211 -0.896629    29104025  \n",
       "16495 -0.899932    35240916  \n",
       "13778 -0.900239    22023976  \n",
       "16496 -0.901838    35240916  \n",
       "13871 -0.950209    23147342  \n",
       "25537 -0.950417    27042898  \n",
       "19295 -0.960278    35273685  \n",
       "14080 -0.974960    23261480  \n",
       "16594 -0.996599    35273673  \n",
       "29655 -1.001798    41076680  \n",
       "12445 -1.005707    23213434  \n",
       "12280 -1.032240    23045280  \n",
       "12882 -1.095383    26085275  \n",
       "15580 -1.112864    31012858  \n",
       "13019 -1.148471    27043452  \n",
       "24998 -1.159292    23160764  \n",
       "14166 -1.165441    23001232  \n",
       "26513 -1.262291    23005653  \n",
       "12034 -1.270642    23050403  \n",
       "3900  -1.303925    31081639  \n",
       "867   -1.325923    26018977  \n",
       "3208  -1.491759    53013352  \n",
       "939   -1.769999    29181429  \n",
       "\n",
       "[33092 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sort_dif = output.sort_values(['dif'],ascending=False)\n",
    "output_sort_dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar as 1000 escolas que mais melhorariam usando esse modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_esc_pred2 = output_sort_dif.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_esc_pred2.to_csv(r'C:\\Users\\Filipe Prates\\Documents\\Projects\\Datasets\\BCG Challenge\\original\\best_schools\\best_esc_pred2(sem_ideb).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
